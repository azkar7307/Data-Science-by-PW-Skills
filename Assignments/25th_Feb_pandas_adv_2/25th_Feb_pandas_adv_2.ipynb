{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /config/.local/lib/python3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /config/.local/lib/python3.8/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /config/.local/lib/python3.8/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /config/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /config/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Consider following code to answer further questions*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        course_name  duration\n",
      "0       Data Scienc         2\n",
      "1  Machine Learning         3\n",
      "2          Big Data         6\n",
      "3     Data Engineer         4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "course_name = ['Data Scienc', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. \n",
    "\n",
    "Write a code to print the data present in the second row of the dataframe, df.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. \n",
    "\n",
    "What is the difference between the functions loc and iloc in pandas.DataFrame?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loc` and `iloc` are two methods in the Pandas DataFrame that are used to retrieve data from specific rows and columns.\n",
    "\n",
    "The main difference between `loc` and `iloc` is in how they access the data:\n",
    "\n",
    "`loc` is label-based and is used to retrieve data by row and column labels. This means that you need to specify the row and column labels to retrieve the data.\n",
    "\n",
    "`iloc` is integer-based and is used to retrieve data by row and column index positions. This means that you need to specify the row and column index positions to retrieve the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. \n",
    "\n",
    "Reindex the given dataframe using a variable, reindex = [3,0,1,2] and store it in the variable, new_df\n",
    "then find the output for both new_df.loc[2] and new_df.iloc[2].\n",
    "\n",
    "Did you observe any difference in both the outputs? If so then explain it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scienc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big Data</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_name  duration\n",
       "3     Data Engineer         4\n",
       "0       Data Scienc         2\n",
       "1  Machine Learning         3\n",
       "2          Big Data         6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_index = [3, 0, 1, 2]\n",
    "new_df = df.reindex(new_index)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Big Data\n",
       "duration              6\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of `new_df.loc[2]` is `course_name Big Data, duration 6`. This is because `loc` uses the label '2' to retrieve the row with the label '2', which in this case corresponds to the row with the course name 'Big Data' and duration '6'.\n",
    "\n",
    "The output of `new_df.iloc[2]` is `course_name Machine Learning, duration 3`. This is because `iloc` uses the integer index position '2' to retrieve the row in the third position (since indexing starts at 0), which corresponds to the row with the course name 'Machine Learning' and duration '3'.\n",
    "\n",
    "As we can see, the output of `new_df.loc[2]` and `new_df.iloc[2]` are different, even though they both correspond to the same row. This is because `loc` and `iloc` use different methods to retrieve the row. `loc` uses the label '2', which corresponds to the row with the course name 'Big Data', while `iloc` uses the integer index position '2', which corresponds to the row with the course name 'Machine Learning'. This demonstrates the importance of understanding the difference between `loc` and `iloc` and using the appropriate method for your needs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Consider the below code to answer further questions:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column_1  column_2  column_3  column_4  column_5  column_6\n",
      "1  0.554567  0.667196  0.870470  0.073612  0.678422  0.311115\n",
      "2  0.661435  0.585993  0.166375  0.322021  0.443642  0.476403\n",
      "3  0.566874  0.234873  0.815815  0.322098  0.131982  0.529500\n",
      "4  0.736682  0.823665  0.134523  0.736321  0.859242  0.999100\n",
      "5  0.449657  0.036116  0.296106  0.045072  0.507166  0.529083\n",
      "6  0.621973  0.451789  0.707761  0.699028  0.765483  0.018293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. \n",
    "\n",
    "Write a code to find the following statistical measurements for the above dataframe df1:\n",
    "\n",
    "(i) mean of each and every column present in the dataframe.\n",
    "\n",
    "(ii) standard deviation of column, ‘column_2’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_1    0.598531\n",
      "column_2    0.466605\n",
      "column_3    0.498509\n",
      "column_4    0.366359\n",
      "column_5    0.564323\n",
      "column_6    0.477249\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# (i) mean of each and every column present in the dataframe.\n",
    "print(df1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2902488281963301\n"
     ]
    }
   ],
   "source": [
    "# (ii) standard deviation of column, ‘column_2’\n",
    "print(df1['column_2'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. \n",
    "Replace the data present in the second row of column, ‘column_2’ by a string variable then find the mean of column, column_2.\n",
    "\n",
    "If you are getting errors in executing it then explain why.\n",
    "\n",
    "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replace the data present in the second row of 'column_2' by a string variable, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[2, 'column_2'] = 'string_variable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column_1         column_2  column_3  column_4  column_5  column_6\n",
      "1  0.554567         0.667196  0.870470  0.073612  0.678422  0.311115\n",
      "2  0.661435  string_variable  0.166375  0.322021  0.443642  0.476403\n",
      "3  0.566874         0.234873  0.815815  0.322098  0.131982  0.529500\n",
      "4  0.736682         0.823665  0.134523  0.736321  0.859242  0.999100\n",
      "5  0.449657         0.036116  0.296106  0.045072  0.507166  0.529083\n",
      "6  0.621973         0.451789  0.707761  0.699028  0.765483  0.018293\n"
     ]
    }
   ],
   "source": [
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the `loc` method to access the cell in the second row of the 'column_2' column and replace its value with the string variable.\n",
    "\n",
    "To find the mean of the 'column_2' column after replacing the second row value with a string, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# try to calculate the mean of 'column_2'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of column_2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11402\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11403\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[39m=\u001b[39maxis, level\u001b[39m=\u001b[39mlevel, skipna\u001b[39m=\u001b[39mskipna, numeric_only\u001b[39m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11354\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11355\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not implement \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39maxis, skipna\u001b[39m=\u001b[39mskipna, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m datetimelike \u001b[39mand\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[39m=\u001b[39m _wrap_results(result, orig_values\u001b[39m.\u001b[39mdtype, fill_value\u001b[39m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[39m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "# try to calculate the mean of 'column_2'\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of column_2:\", mean_column_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this code raises a `TypeError` because we are trying to calculate the mean of a column containing a non-numeric value ('string_variable'). To avoid this error, we need to make sure that all values in the 'column_2' column are numeric before calculating the mean. We can use the `pd.to_numeric()` method with errors='coerce' parameter to convert the column to numeric type and replace any non-numeric values with NaN, as shown in my previous answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. \n",
    "\n",
    "What do you understand about the windows function in pandas and list the types of windows functions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, a window function is a type of function that applies a calculation to a subset of rows in a DataFrame, known as a \"window\", where the subset of rows is defined by a sliding window of fixed size.\n",
    "\n",
    "Window functions can be used to perform various types of calculations, such as moving averages, cumulative sums, rolling aggregations, etc. They are particularly useful for time-series data or any data that has a natural ordering, where we want to calculate a statistic over a rolling window of data points.\n",
    "\n",
    "There are several types of window functions available in pandas, including:\n",
    "\n",
    "* `Rolling`: This function provides rolling window calculations by defining a fixed window size and then applying a function to the values in each window.\n",
    "* `Expanding`: This function applies a function to all the values in the DataFrame up to the current row.\n",
    "* `EWM`: Exponentially weighted moving average is another type of window function where the weights assigned to each data point decreases exponentially over time.\n",
    "* `GroupBy`: The groupby function can also be used as a window function to calculate aggregates over a rolling window of rows for each group.\n",
    "\n",
    "These window functions can be used with various statistical and mathematical functions like sum, mean, median, std, min, max, etc. to calculate the desired statistic over the defined window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. \n",
    "\n",
    "Write a code to print only the current month and year at the time of answering this question.\n",
    "\n",
    "[Hint: Use pandas.datetime function]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month and year: 3 2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2049/2274285597.py:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  current_time = pd.datetime.now()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "current_time = pd.datetime.now()\n",
    "current_month = current_time.month\n",
    "current_year = current_time.year\n",
    "\n",
    "print(\"Current month and year:\", current_month, current_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2049/3174630878.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  pd.datetime.now()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 3, 19, 9, 51, 5, 662073)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8. \n",
    "\n",
    "Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and calculates the difference between them in days hours, and minutes using Pandas time delta. The program should prompt the user to enter the dates and display the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the Python program that prompts the user to input two dates in the format YYYY-MM-DD and calculates the difference between them in days, hours, and minutes using pandas timedelta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996-12-10\n",
      "2023-3-19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt user to input two dates in YYYY-MM-DD format\n",
    "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# date1 = \"1996-12-10\"\n",
    "# date2 = \"2023-3-19\"\n",
    "\n",
    "print(date1)\n",
    "print(date2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996-12-10 00:00:00\n",
      "2023-03-19 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the input strings to pandas datetime objects\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "print(date1)\n",
    "print(date2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9595 days 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the time difference using pandas timedelta\n",
    "time_diff = date2 - date1\n",
    "print(time_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference between 1996-12-10 and 2023-03-19 is:\n",
      "9595 days 0 hours 0 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract days, hours, and minutes from the timedelta object\n",
    "days_diff = time_diff.days\n",
    "hours_diff = time_diff.seconds // 3600\n",
    "minutes_diff = (time_diff.seconds % 3600) // 60\n",
    "\n",
    "# Display the result\n",
    "print(\"Time difference between\", date1.date(), \"and\", date2.date(), \"is:\")\n",
    "print(days_diff, \"days\", hours_diff, \"hours\", minutes_diff, \"minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9. \n",
    "\n",
    "Write a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program should prompt the user to enter the file path, column name, and category order, and then display the sorted data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program prompts the user to enter the file path, column name, and category order, and then displays the sorted data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "\n",
    "# Prompt user to enter file path and column name\n",
    "file_path = input(\"Enter the file path: \")\n",
    "column_name = input(\"Enter the column name: \")\n",
    "\n",
    "# Read CSV file into a pandas dataframe\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Prompt user to enter category order\n",
    "categories = input(\"Enter the category order (comma-separated): \").split(',')\n",
    "\n",
    "# Convert column to categorical data type\n",
    "data[column_name] = pd.Categorical(data[column_name], categories=categories, ordered=True)\n",
    "\n",
    "# Sort data by the categorical column\n",
    "data = data.sort_values(column_name)\n",
    "\n",
    "# Display the sorted data\n",
    "print(data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program first prompts the user to enter the file path and column name using the `input()` function. The program then reads the CSV file into a pandas dataframe using the `pd.read_csv()` function.\n",
    "\n",
    "The program then prompts the user to enter the category order as a comma-separated list of strings, which is then converted to a list using the `split()` function.\n",
    "\n",
    "Next, the program converts the specified column to a categorical data type using the `pd.Categorical()` function, specifying the category order and setting `ordered=True` to ensure that the categories are treated as an ordered set.\n",
    "\n",
    "Finally, the program sorts the data by the categorical column using the `sort_values()` function and displays the sorted data using the `print()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10. \n",
    "\n",
    "Write a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program should prompt the user to enter the file path and display the chart.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program prompts the user to enter the file path and displays the chart:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt user to enter file path\n",
    "file_path = input(\"Enter the file path: \")\n",
    "\n",
    "# Read CSV file into a pandas dataframe\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert date column to datetime data type\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "# Pivot data to create a multi-index dataframe with product categories as columns and dates as rows\n",
    "data_pivot = pd.pivot_table(data, values='sales', index=['date'], columns=['product_category'], aggfunc=sum)\n",
    "\n",
    "# Plot stacked bar chart\n",
    "ax = data_pivot.plot(kind='bar', stacked=True)\n",
    "\n",
    "# Set chart title and axis labels\n",
    "plt.title('Sales by Product Category')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program first prompts the user to enter the file path using the `input()` function. The program then reads the CSV file into a pandas dataframe using the `pd.read_csv()` function.\n",
    "\n",
    "The program then converts the date column to a datetime data type using the `pd.to_datetime()` function. The data is then pivoted using the `pd.pivot_table()` function to create a multi-index dataframe with product categories as columns and dates as rows.\n",
    "\n",
    "Next, the program plots a stacked bar chart using the `plot()` function of the pivoted dataframe. The `kind='bar'` argument specifies that a bar chart should be created, and `stacked=True` specifies that the bars should be stacked on top of each other.\n",
    "\n",
    "Finally, the program sets the chart title and axis labels using the `title()`, `xlabel()`, and `ylabel()` functions, and displays the chart using the `show()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q11. \n",
    "\n",
    "You are given a CSV file containing student data that includes the student ID and their test score. Write\n",
    "a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
    "displays the results in a table.\n",
    "\n",
    "The program should do the following:\n",
    "\n",
    "* Prompt the user to enter the file path of the CSV file containing the student data\n",
    "* Read the CSV file into a Pandas DataFrame\n",
    "* Calculate the mean, median, and mode of the test scores using Pandas tools\n",
    "* Display the mean, median, and mode in a table.\n",
    "\n",
    "Assume the CSV file contains the following columns:\n",
    "\n",
    "* Student ID: The ID of the student\n",
    "* Test Score: The score of the student's test.\n",
    "\n",
    "Example usage of the program:\n",
    "```\n",
    "Enter the file path of the CSV file containing the student data: student_data.csv\n",
    "\n",
    "+-----------+--------+\n",
    "| Statistic | Value |\n",
    "+-----------+--------+\n",
    "| Mean | 79.6 |\n",
    "| Median | 82 |\n",
    "| Mode | 85, 90 |\n",
    "+-----------+--------+\n",
    "```\n",
    "\n",
    "Assume that the CSV file student_data.csv contains the following data:\n",
    "\n",
    "Student ID,Test Score\n",
    "\n",
    "1,85\n",
    "\n",
    "2,90\n",
    "\n",
    "3,80\n",
    "\n",
    "4,75\n",
    "\n",
    "5,85\n",
    "\n",
    "6,82\n",
    "\n",
    "7,78\n",
    "\n",
    "8,85\n",
    "\n",
    "9,90\n",
    "\n",
    "10,85\n",
    "\n",
    "\n",
    "The program should calculate the mean, median, and mode of the test scores and display the results\n",
    "in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Statistic  Value\n",
      "0      mean   83.5\n",
      "1    median   85.0\n",
      "2      mode   85.0\n"
     ]
    }
   ],
   "source": [
    "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "stats_df = pd.DataFrame(data={\"Statistic\": ['mean', 'median', 'mode'], \\\n",
    "                                \"Value\":[df['Test Score'].mean(), \\\n",
    "                                         df['Test Score'].median(), \\\n",
    "                                         df['Test Score'].mode()[0]\n",
    "                                        ]\n",
    "                             }\n",
    "                        )\n",
    "\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
